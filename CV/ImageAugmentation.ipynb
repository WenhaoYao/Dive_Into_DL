{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_augs = torchvision.transforms.Compose([torchvision.transforms.RandomHorizontalFlip(),\n",
    "                torchvision.transforms.ToTensor()])\n",
    "test_augs = train_augs = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def load_cifar10(is_train, augs, batch_size):\n",
    "    dataset = torchvision.datasets.CIFAR10(root='../data', train=is_train,\n",
    "                transform=augs,download=True)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, shuffle=is_train,\n",
    "                batch_size=batch_size, num_workers=d2l.get_dataloader_workers())\n",
    "    return dataloader"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def accuracy(y_hat, y):\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "    return float(cmp.type(y.dtype).sum())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def evaluate_accuracy(net, data_iter, device=None):\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.eval()\n",
    "        if not device:\n",
    "            device = next(iter(net.parameters())).device\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        acc, length = 0.0, 0.0\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(X, list):\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            acc += accuracy(net(X), y)\n",
    "            length += len(X)\n",
    "    return acc/length"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def train_batch(net, X, y, loss, trainer, device):\r\n",
    "    if isinstance(X, list):\r\n",
    "        X = [x.to(device) for x in X]\r\n",
    "    else:\r\n",
    "        X = X.to(device)\r\n",
    "    y = y.to(device)\r\n",
    "    net.train()\r\n",
    "    trainer.zero_grad()\r\n",
    "    pred = net(X)\r\n",
    "    l = loss(pred, y)\r\n",
    "    l.sum().backward()\r\n",
    "    trainer.step()\r\n",
    "    train_loss_sum = l.sum()\r\n",
    "    train_acc_sum = accuracy(pred, y)\r\n",
    "    return train_loss_sum, train_acc_sum\r\n",
    "\r\n",
    "def train(net, train_iter, test_iter, loss,trainer, num_epochs, device):\r\n",
    "    net = net.to(device)\r\n",
    "    for epoch in range(num_epochs):\r\n",
    "        print(f'epoch:{epoch}')\r\n",
    "        l, acc = None, None \r\n",
    "        for i, (features, labels) in enumerate(train_iter):\r\n",
    "            l, acc = train_batch(net, features, labels, loss, trainer, device)\r\n",
    "            l += l\r\n",
    "            acc += acc\r\n",
    "        print(f'loss:{l/(i+1)}, train_acc:{acc/(i+1)}')\r\n",
    "        test_acc = evaluate_accuracy(net, test_iter)\r\n",
    "        print(f'test_acc:{test_acc}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "batch_size, device, net = 256, torch.device('cuda:1'), d2l.resnet18(10, 3)\r\n",
    "\r\n",
    "def init_weights(m):\r\n",
    "    if type(m) in [nn.Linear, nn.Conv2d]:\r\n",
    "        nn.init.xavier_uniform_(m.weight)\r\n",
    "\r\n",
    "net.apply(init_weights)\r\n",
    "\r\n",
    "def train_with_data_aug(train_augs, test_augs, net,batch_size, lr=0.001):\r\n",
    "    train_iter = load_cifar10(True, train_augs, batch_size)\r\n",
    "    test_iter = load_cifar10(False, test_augs, batch_size)\r\n",
    "    loss = nn.CrossEntropyLoss(reduction=\"none\")\r\n",
    "    trainer = torch.optim.Adam(net.parameters(), lr)\r\n",
    "    train(net, train_iter, test_iter, loss, trainer, 10, device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_with_data_aug(train_augs, test_augs, net, batch_size)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('d2l': conda)"
  },
  "interpreter": {
   "hash": "4eac56508231727220c31c43b40c5f47a06b529c4865115006b415545aec1389"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}